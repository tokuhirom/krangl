{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"This is the manual of krangl . krangl is an open-source {K}otlin library for data w{rangl}ing. By implementing a grammar of data manipulation using a modern functional-style API, it allows to filter, transform, aggregate and reshape tabular data. krangl tries to become what pandas is for python , and readr + tidyr + dplyr are for R. krangl is open-source and developed on github. For a first primer see KotlinConf 2019 slides about Data Science with kotlin Features Filter, transform, aggregate and reshape tabular data Modern, user-friendly and easy-to-learn data-science API Reads from plain and compressed tsv, csv, json, or any delimited format with or without header from local or remote Supports grouped operations Ships with JDBC support Tables can contain atomic columns (int, double, boolean) as well as object columns Reshape tables from wide to long and back Table joins (left, right, semi, inner, outer) Cross tabulation Descriptive statistics (mean, min, max, median, ...) Functional API inspired by dplyr , pandas , and Kotlin stdlib Furthermore, it provides methods to go back and forth between untyped and typed data. Installation To get started simply add it as a dependency: repositories { mavenCentral () } dependencies { implementation \"com.github.holgerbrandl:krangl:0.17.2\" } Declaring the repository is purely optional as it is the default already. If you're very new to Kotlin and Gradle you may want to read first about its basic syntax , some basic IDE features and about how to use gradle to configure dependencies in Kotlin projects. Example Flights that departed NYC, are grouped by date, some columns of interest are selected, dasummarized to reveal mean departure and arrival delays, and finally just those dates are kept that show extreme delays. flights . groupBy ( \"year\" , \"month\" , \"day\" ) . select ({ range ( \"year\" , \"day\" ) }, { listOf ( \"arr_delay\" , \"dep_delay\" ) }) . summarize ( \"mean_arr_delay\" to { it [ \"arr_delay\" ] . mean ( removeNA = true ) }, \"mean_dep_delay\" to { it [ \"dep_delay\" ] . mean ( removeNA = true ) } ) . filter { ( it [ \"mean_arr_delay\" ] gt 30 ) OR ( it [ \"mean_dep_delay\" ] gt 30 ) }","title":"Introduction"},{"location":"#features","text":"Filter, transform, aggregate and reshape tabular data Modern, user-friendly and easy-to-learn data-science API Reads from plain and compressed tsv, csv, json, or any delimited format with or without header from local or remote Supports grouped operations Ships with JDBC support Tables can contain atomic columns (int, double, boolean) as well as object columns Reshape tables from wide to long and back Table joins (left, right, semi, inner, outer) Cross tabulation Descriptive statistics (mean, min, max, median, ...) Functional API inspired by dplyr , pandas , and Kotlin stdlib Furthermore, it provides methods to go back and forth between untyped and typed data.","title":"Features"},{"location":"#installation","text":"To get started simply add it as a dependency: repositories { mavenCentral () } dependencies { implementation \"com.github.holgerbrandl:krangl:0.17.2\" } Declaring the repository is purely optional as it is the default already. If you're very new to Kotlin and Gradle you may want to read first about its basic syntax , some basic IDE features and about how to use gradle to configure dependencies in Kotlin projects.","title":"Installation"},{"location":"#example","text":"Flights that departed NYC, are grouped by date, some columns of interest are selected, dasummarized to reveal mean departure and arrival delays, and finally just those dates are kept that show extreme delays. flights . groupBy ( \"year\" , \"month\" , \"day\" ) . select ({ range ( \"year\" , \"day\" ) }, { listOf ( \"arr_delay\" , \"dep_delay\" ) }) . summarize ( \"mean_arr_delay\" to { it [ \"arr_delay\" ] . mean ( removeNA = true ) }, \"mean_dep_delay\" to { it [ \"dep_delay\" ] . mean ( removeNA = true ) } ) . filter { ( it [ \"mean_arr_delay\" ] gt 30 ) OR ( it [ \"mean_dep_delay\" ] gt 30 ) }","title":"Example"},{"location":"10_minutes/","text":"krangl in 3 Minutes Welcome to krangl . Relational data and how to handle it properly is a huge topic, but the core concepts are relatively simple. So let's get started! Columns and Rows DataFrames are just tables with type constraints within each column. To glance into them horizontally and vertically we can do irisData . print ( maxRows = 10 ) irisData . schema () irisData is bundled with krangl, and gives the measurements in centimeters of the variables sepal length and width and petal length and width, respectively, for 50 flowers from each of 3 species of iris. The species are Iris setosa, versicolor, and virginica. Columns and Rows can be accessed using krangl with val col = irisData [ \"Species\" ] val cell = irisData [ \"Species\" ][ 1 ] Get your data into krangl To save a data frame simply use irisData . writeCSV ( File ( \"my_iris.txt\" )) To load a data-frame simply {done} irisData . writeCSV ( File ( \"my_iris.txt\" )) It allows to Read from tsv, csv, json, jdbc, e.g. val tornados = DataFrame . readCSV ( pathAsStringFileOrUrl ) tornados . writeCSV ( File ( \"tornados.txt.gz\" )) krangl will guess column types unless the user provides a column type model. You can also simply define new data-frames in place val users : DataFrame = dataFrameOf ( \"firstName\" , \"lastName\" , \"age\" , \"hasSudo\" )( \"max\" , \"smith\" , 53 , false , \"eva\" , \"miller\" , 23 , true , null , \"meyer\" , 23 , null ) Note krangl also allows to convert any iterable into a data-frame via reflection. See the section about Reshaping Data for details. Other input formats krangl also allows to read in json array data. For a complete overview see JsonIO val df = fromJson ( \"my.json\" ) val df2 = fromJson ( \"http://foo.bar/my.json\" )","title":"10 Minute Tutorial"},{"location":"10_minutes/#krangl-in-3-minutes","text":"Welcome to krangl . Relational data and how to handle it properly is a huge topic, but the core concepts are relatively simple. So let's get started!","title":"krangl in 3 Minutes"},{"location":"10_minutes/#columns-and-rows","text":"DataFrames are just tables with type constraints within each column. To glance into them horizontally and vertically we can do irisData . print ( maxRows = 10 ) irisData . schema () irisData is bundled with krangl, and gives the measurements in centimeters of the variables sepal length and width and petal length and width, respectively, for 50 flowers from each of 3 species of iris. The species are Iris setosa, versicolor, and virginica. Columns and Rows can be accessed using krangl with val col = irisData [ \"Species\" ] val cell = irisData [ \"Species\" ][ 1 ]","title":"Columns and Rows"},{"location":"10_minutes/#get-your-data-into-krangl","text":"To save a data frame simply use irisData . writeCSV ( File ( \"my_iris.txt\" )) To load a data-frame simply {done} irisData . writeCSV ( File ( \"my_iris.txt\" )) It allows to Read from tsv, csv, json, jdbc, e.g. val tornados = DataFrame . readCSV ( pathAsStringFileOrUrl ) tornados . writeCSV ( File ( \"tornados.txt.gz\" )) krangl will guess column types unless the user provides a column type model. You can also simply define new data-frames in place val users : DataFrame = dataFrameOf ( \"firstName\" , \"lastName\" , \"age\" , \"hasSudo\" )( \"max\" , \"smith\" , 53 , false , \"eva\" , \"miller\" , 23 , true , null , \"meyer\" , 23 , null ) Note krangl also allows to convert any iterable into a data-frame via reflection. See the section about Reshaping Data for details.","title":"Get your data into krangl"},{"location":"10_minutes/#other-input-formats","text":"krangl also allows to read in json array data. For a complete overview see JsonIO val df = fromJson ( \"my.json\" ) val df2 = fromJson ( \"http://foo.bar/my.json\" )","title":"Other input formats"},{"location":"about/","text":"About License krangl is licensed under MIT License. Acknowledgements kalasim started off as a blunt rewrite of dplyr . and we are deeply thankful for its permissive licence that enabled setting up this project. References Similar APIs (not just Kotlin) Scala DataTable : a lightweight, in-memory table structure written in Scala joinery implements data frames for Java tablesaw which is (according to its authors) the The simplest way to slice data in Java paleo which provides immutable Java 8 data frames with typed columns agate isa Python data analysis library that is optimized for humans instead of machines pandas provides high-performance, easy-to-use data structures and data analysis tools for python ( cheatsheet ) dplyr which is a grammar of data manipulation (R-lang) morpheus-core which is a data science framework implementing an R-like data-frame for the JVM Frameless is a Scala library for working with Spark using more expressive types, including a more strongly typed Dataset/ DataFrame API https://dataframes.juliadata.org/stable/ A modern recent addition to the Julia data-science ecosystem Other data-science projects vectorz is a fast and flexible numerical library for Java featuring N-dimensional arrays koma is a scientific computing library written in Kotlin, designed to allow development of cross-platform numerical applications termsql converts text from a file or from stdin into SQL table and query it instantly. Uses sqlite as backend. kotliquery is a handy database access library Dex : The Data Explorer is a data visualization tool written capable of powerful ETL and publishing web visualizations Data Visualization kravis which implements a Kotlin DSL for scientific data visualization XChart is a light weight Java library for plotting data Charts in TornadoFX provide visualzation examples using javaFX Repo Maintainer Holger Brandl holds a Ph.D. degree in machine learning and has developed new concepts in the field of computational linguistics. More recently he has co-authored publications in high-ranking journals such as Nature and Science. To stay in sync with what's happening in tech, he's developing open-source tools, methods and algorithms for bioinformatics, high-performance computing and data science. He's passionate about data science, machine learning, kotlin, R, elegant APIs and data visualisation in particular in relations applications from systems biology and industrial manufacturing.","title":"About"},{"location":"about/#about","text":"","title":"About"},{"location":"about/#license","text":"krangl is licensed under MIT License.","title":"License"},{"location":"about/#acknowledgements","text":"kalasim started off as a blunt rewrite of dplyr . and we are deeply thankful for its permissive licence that enabled setting up this project.","title":"Acknowledgements"},{"location":"about/#references","text":"Similar APIs (not just Kotlin) Scala DataTable : a lightweight, in-memory table structure written in Scala joinery implements data frames for Java tablesaw which is (according to its authors) the The simplest way to slice data in Java paleo which provides immutable Java 8 data frames with typed columns agate isa Python data analysis library that is optimized for humans instead of machines pandas provides high-performance, easy-to-use data structures and data analysis tools for python ( cheatsheet ) dplyr which is a grammar of data manipulation (R-lang) morpheus-core which is a data science framework implementing an R-like data-frame for the JVM Frameless is a Scala library for working with Spark using more expressive types, including a more strongly typed Dataset/ DataFrame API https://dataframes.juliadata.org/stable/ A modern recent addition to the Julia data-science ecosystem Other data-science projects vectorz is a fast and flexible numerical library for Java featuring N-dimensional arrays koma is a scientific computing library written in Kotlin, designed to allow development of cross-platform numerical applications termsql converts text from a file or from stdin into SQL table and query it instantly. Uses sqlite as backend. kotliquery is a handy database access library Dex : The Data Explorer is a data visualization tool written capable of powerful ETL and publishing web visualizations Data Visualization kravis which implements a Kotlin DSL for scientific data visualization XChart is a light weight Java library for plotting data Charts in TornadoFX provide visualzation examples using javaFX","title":"References"},{"location":"about/#repo-maintainer","text":"Holger Brandl holds a Ph.D. degree in machine learning and has developed new concepts in the field of computational linguistics. More recently he has co-authored publications in high-ranking journals such as Nature and Science. To stay in sync with what's happening in tech, he's developing open-source tools, methods and algorithms for bioinformatics, high-performance computing and data science. He's passionate about data science, machine learning, kotlin, R, elegant APIs and data visualisation in particular in relations applications from systems biology and industrial manufacturing.","title":"Repo Maintainer"},{"location":"apidocs/","text":"Built with love and dokka , we also provide Krangl API Docs .","title":"API Docs"},{"location":"data_manip/","text":"Add columns with addColumn val df : DataFrame = dataFrameOf ( \"first_name\" , \"last_name\" , \"age\" , \"weight\" )( \"Max\" , \"Doe\" , 23 , 55 , \"Franz\" , \"Smith\" , 23 , 88 , \"Horst\" , \"Keanes\" , 12 , 82 ) df . addColumn ( \"salary_category\" ) { 3 } // add constants df . addColumn ( \"age_3y_later\" ) { it [ \"age\" ] + 3 } // do basic column arithmetics // krangl dataframes are immutable so we need to (re)assign results to preserve changes. val newDF = df . addColumn ( \"full_name\" ) { it [ \"first_name\" ] + \" \" + it [ \"last_name\" ] } // krangl overloads arithmetic operators like + for dataframe-columns df . addColumn ( \"user_id\" ) { it [ \"last_name\" ] + \"_id\" + rowNumber } //and provides convenience methods to ignore NAs df . addColumn ( \"first_name_initial\" ) { it [ \"first_name\" ] . map < String > { it . first () } } // or add multiple columns at once df . addColumns ( \"age_plus3\" to { it [ \"age\" ] + 3 }, \"initial\" to { it [ \"first_name\" ] . map < String > { it . first () } } ) To make create columns starting with constant values those need to be expanded to static columns using with const df.createColumn(\"user_id\") { const(\"id\") + nrow } Get your data in order with sortedBy df . sortedBy ( \"age\" ) // and add secondary sorting attributes as varargs df . sortedBy ( \"age\" , \"weight\" ) // reverse sorting order df . sortedByDescending ( \"age\" ) df . sortedBy { desc ( \"age\" ) } // sort descending by age, and resolve ties by weight df . sortedBy ({ desc ( it [ \"age\" ] ) }, { it [ \"weight\" ] }) // sort with indicator lambda df . sortedBy { it [ \"weight\" ] . round () } ??? mimic Kotlin stdlib where possible Subset variables with select // positive selection df . select ( \"last_name\" , \"weight\" ) // negative selection df . remove ( \"weight\" , \"age\" ) // selector mini-language df . select { endsWith ( \"name\" ) } df . select { matches ( \"foo[0-9\" ) } // functional style column selection // odd name to avoid JVM signature clash (help welcome!) df . select2 { it is IntCol } // rename columns df . rename ( \"last_name\" to \"Nachname\" ) {% hint style=\"warning\" %} Be aware that the usage of string constants as function literals is legit kotlin code sleepData.sortedBy{ \"order\" } but lacks select semantics. krangl will throw an error in such a case. {% endhint %} Subset your records with filter // Subset rows with vectorized filter df . filter { it [ \"age\" ] eq 23 } df . filter { it [ \"weight\" ] gt 50 } df . filter ({ it [ \"last_name\" ] . isMatching { startsWith ( \"Do\" ) }}) In case vectorized operations are not possible or available we can also filter tables by row which allows for scalar operators df . filterByRow { it [ \"age\" ] as Int > 5 } df . filterByRow { ( it [ \"age\" ] as Int ). rem ( 10 ) == 0 } // \"round\" birthdays :-) Summarize your data with summarize // do simple cross tabulations df . count ( \"age\" , \"last_name\" ) // ... or calculate single summary statistic df . summarize ( \"mean_age\" ) { it [ \"age\" ] . mean ( true ) } // ... or multiple summary statistics df . summarize ( \"min_age\" to { it [ \"age\" ] . min () }, \"max_age\" to { it [ \"age\" ] . max () } ) // for sake of r and python transition you can also use `=` here df . summarize ( \"min_age\" ` = ` { it [ \"age\" ] . min () }, \"max_age\" ` = ` { it [ \"age\" ] . max () } ) Perform grouped operations after groupBy val groupedDf : DataFrame = df . groupBy ( \"age\" ) // ... or provide multiple grouping attributes with varargs val sumDF = groupedDf . summarize ( \"mean_weight\" to { it [ \"weight\" ] . mean ( removeNA = true ) }, \"num_persons\" to { nrow } ) // Optionally ungroup the data sumDF . ungroup () Bring it all together flightsData . groupBy ( \"year\" , \"month\" , \"day\" ) . select ({ range ( \"year\" , \"day\" ) }, { listOf ( \"arr_delay\" , \"dep_delay\" ) }) . summarize ( \"mean_arr_delay\" ` = ` { it [ \"arr_delay\" ] . mean ( removeNA = true ) }, \"mean_dep_delay\" to { it [ \"dep_delay\" ] . mean ( removeNA = true ) } ) . filter { ( it [ \"mean_arr_delay\" ] gt 30 ) OR ( it [ \"mean_dep_delay\" ] gt 30 ) } . sortedBy ( \"mean_arr_delay\" ) year month day mean_arr_delay mean_dep_delay 2013 10 11 18.9229 31.2318 2013 5 24 24.2574 30.3407 2013 6 2 26.075 34.0133 2013 6 26 27.3174 30.61175 2013 6 10 28.0222 30.61945 2013 7 8 29.6488 37.2966 2013 8 22 29.9767 33.6004 2013 2 27 31.252 37.7632 Note Both = and to are supported in table expressions. Summarize Data with summarize Examples Add a suffix to some column names // first select column names to be altered irisData . names . filter { it . startsWith ( \"Sepal\" ) }. map { // second, apply renaming oldName -> irisData . rename ( oldName to ( \"My\" + oldName )) }","title":"Data Manipulation"},{"location":"data_manip/#add-columns-with-addcolumn","text":"val df : DataFrame = dataFrameOf ( \"first_name\" , \"last_name\" , \"age\" , \"weight\" )( \"Max\" , \"Doe\" , 23 , 55 , \"Franz\" , \"Smith\" , 23 , 88 , \"Horst\" , \"Keanes\" , 12 , 82 ) df . addColumn ( \"salary_category\" ) { 3 } // add constants df . addColumn ( \"age_3y_later\" ) { it [ \"age\" ] + 3 } // do basic column arithmetics // krangl dataframes are immutable so we need to (re)assign results to preserve changes. val newDF = df . addColumn ( \"full_name\" ) { it [ \"first_name\" ] + \" \" + it [ \"last_name\" ] } // krangl overloads arithmetic operators like + for dataframe-columns df . addColumn ( \"user_id\" ) { it [ \"last_name\" ] + \"_id\" + rowNumber } //and provides convenience methods to ignore NAs df . addColumn ( \"first_name_initial\" ) { it [ \"first_name\" ] . map < String > { it . first () } } // or add multiple columns at once df . addColumns ( \"age_plus3\" to { it [ \"age\" ] + 3 }, \"initial\" to { it [ \"first_name\" ] . map < String > { it . first () } } ) To make create columns starting with constant values those need to be expanded to static columns using with const df.createColumn(\"user_id\") { const(\"id\") + nrow }","title":"Add columns with addColumn"},{"location":"data_manip/#get-your-data-in-order-with-sortedby","text":"df . sortedBy ( \"age\" ) // and add secondary sorting attributes as varargs df . sortedBy ( \"age\" , \"weight\" ) // reverse sorting order df . sortedByDescending ( \"age\" ) df . sortedBy { desc ( \"age\" ) } // sort descending by age, and resolve ties by weight df . sortedBy ({ desc ( it [ \"age\" ] ) }, { it [ \"weight\" ] }) // sort with indicator lambda df . sortedBy { it [ \"weight\" ] . round () } ??? mimic Kotlin stdlib where possible","title":"Get your data in order with sortedBy"},{"location":"data_manip/#subset-variables-with-select","text":"// positive selection df . select ( \"last_name\" , \"weight\" ) // negative selection df . remove ( \"weight\" , \"age\" ) // selector mini-language df . select { endsWith ( \"name\" ) } df . select { matches ( \"foo[0-9\" ) } // functional style column selection // odd name to avoid JVM signature clash (help welcome!) df . select2 { it is IntCol } // rename columns df . rename ( \"last_name\" to \"Nachname\" ) {% hint style=\"warning\" %} Be aware that the usage of string constants as function literals is legit kotlin code sleepData.sortedBy{ \"order\" } but lacks select semantics. krangl will throw an error in such a case. {% endhint %}","title":"Subset variables with select"},{"location":"data_manip/#subset-your-records-with-filter","text":"// Subset rows with vectorized filter df . filter { it [ \"age\" ] eq 23 } df . filter { it [ \"weight\" ] gt 50 } df . filter ({ it [ \"last_name\" ] . isMatching { startsWith ( \"Do\" ) }}) In case vectorized operations are not possible or available we can also filter tables by row which allows for scalar operators df . filterByRow { it [ \"age\" ] as Int > 5 } df . filterByRow { ( it [ \"age\" ] as Int ). rem ( 10 ) == 0 } // \"round\" birthdays :-)","title":"Subset your records with filter"},{"location":"data_manip/#summarize-your-data-with-summarize","text":"// do simple cross tabulations df . count ( \"age\" , \"last_name\" ) // ... or calculate single summary statistic df . summarize ( \"mean_age\" ) { it [ \"age\" ] . mean ( true ) } // ... or multiple summary statistics df . summarize ( \"min_age\" to { it [ \"age\" ] . min () }, \"max_age\" to { it [ \"age\" ] . max () } ) // for sake of r and python transition you can also use `=` here df . summarize ( \"min_age\" ` = ` { it [ \"age\" ] . min () }, \"max_age\" ` = ` { it [ \"age\" ] . max () } )","title":"Summarize your data with summarize"},{"location":"data_manip/#perform-grouped-operations-after-groupby","text":"val groupedDf : DataFrame = df . groupBy ( \"age\" ) // ... or provide multiple grouping attributes with varargs val sumDF = groupedDf . summarize ( \"mean_weight\" to { it [ \"weight\" ] . mean ( removeNA = true ) }, \"num_persons\" to { nrow } ) // Optionally ungroup the data sumDF . ungroup ()","title":"Perform grouped operations after groupBy"},{"location":"data_manip/#bring-it-all-together","text":"flightsData . groupBy ( \"year\" , \"month\" , \"day\" ) . select ({ range ( \"year\" , \"day\" ) }, { listOf ( \"arr_delay\" , \"dep_delay\" ) }) . summarize ( \"mean_arr_delay\" ` = ` { it [ \"arr_delay\" ] . mean ( removeNA = true ) }, \"mean_dep_delay\" to { it [ \"dep_delay\" ] . mean ( removeNA = true ) } ) . filter { ( it [ \"mean_arr_delay\" ] gt 30 ) OR ( it [ \"mean_dep_delay\" ] gt 30 ) } . sortedBy ( \"mean_arr_delay\" ) year month day mean_arr_delay mean_dep_delay 2013 10 11 18.9229 31.2318 2013 5 24 24.2574 30.3407 2013 6 2 26.075 34.0133 2013 6 26 27.3174 30.61175 2013 6 10 28.0222 30.61945 2013 7 8 29.6488 37.2966 2013 8 22 29.9767 33.6004 2013 2 27 31.252 37.7632 Note Both = and to are supported in table expressions.","title":"Bring it all together"},{"location":"data_manip/#summarize-data-with-summarize","text":"","title":"Summarize Data with summarize"},{"location":"data_manip/#examples","text":"Add a suffix to some column names // first select column names to be altered irisData . names . filter { it . startsWith ( \"Sepal\" ) }. map { // second, apply renaming oldName -> irisData . rename ( oldName to ( \"My\" + oldName )) }","title":"Examples"},{"location":"data_model/","text":"Data model of krangl What is a DataFrame? A \"tabular\" data structure representing cases/records (rows), each of which consists of a number of observations or measurements (columns) reference And by mapping this defintion to Kotlin code, we obtain the core abstraction of krangl : interface DataFrame { val cols : List < DataCol > } abstract class DataCol ( val name : String ) { abstract fun values (): Array <*> } * Implemented as column model to allow for vectorization where possible * Column implementations using nullable types String? , Int? , Double? , Boolean? and Any? * Internal length and type consistency checks (e.g. prevent duplicated column names) To type or not to type? Static types are cool, but most data has no type It's more robust/fun to use types and they allow for better design Many data attributes are very fluent data class Employee ( val id : Int , val name : String ) val staffStats = listOf ( Employee ( 1 , \"John\" ), Employee ( 2 , \"Anna\" )) . predictNumSickDays () // new type! . addPerformanceMetrics () // new type! . addSalaries () // new type! . correlationAnalysis () // odd generic signature :-| * R/python lack static typing, which make such workflows more fluent/fun to write staff %>% mutate ( sick_days = predictSickDays ( name )) %>% # table with another column left_join ( userPerf ) %>% # and some more columns left_join ( salaries ) %>% # and even more columns select_if ( is.numeric ) %>% correlate ( type = \"spearman\" ) # correlate numeric attributes Defining types is a tedious process. krangl allows to mix typed and untyped data in a tablular data structure: val dataFrame : DataFrame = employee:Employee sales:List<Sale> age:Int address:String salary:Double Employee(23, \"Max\") listOf(Sale(...), Sale()) 23 \"Frankfurt\" 50.3E3 ... ... ... ... ... It implements a pandas / tidyverse like API to create, manipulate, reshape, combine and summarize data frames // aggregations like dataFrame . groupBy ( \"age\" ). count () dataFrame . summarize ( \"mean_salary\" ){ mean ( it [ \"salaray\" ] )} // integration like val df : DataFrame = dataFrame . leftJoin ( otherDF ) // transformations like dataFrame . addColumn ( \"intial\" ){ it [ \"employee\" ] . map < Employee > { it . name . first () }} Get your data into krangl It allows to read from tsv, csv, json, jdbc, e.g. val users = dataFrameOf ( \"firstName\" , \"lastName\" , \"age\" , \"hasSudo\" )( null , \"meyer\" , 23 , null ) val tornados = DataFrame . readCSV ( pathAsStringFileOrUrl ) tornados . writeCSV ( File ( \"tornados.txt.gz\" )) Guess column types & default parameters Built-in missing value support Convert any iterable into a data-frame via extension function + reflection data class Person ( val name : String , val address : String ) val persons : List < Person > = ... val personsDF : DataFrame = persons . asDataFrame () When doing so non-basic properties will be preserved as AnyCol . To further destructured these we can use unfold : data class City ( val name : String , val code : Int ) data class Person ( val name : String , val address : City ) val persons : List < Person > = listOf ( Person ( \"Max\" , City ( \"Dresden\" , 12309 )), Person ( \"Anna\" , City ( \"Berlin\" , 10115 )) ) val personsDF : DataFrame = persons . asDataFrame () personsDF . unfold < City > ( \"address\" ) Both the column and the type are provided.","title":"Data Model"},{"location":"data_model/#data-model-of-krangl","text":"What is a DataFrame? A \"tabular\" data structure representing cases/records (rows), each of which consists of a number of observations or measurements (columns) reference And by mapping this defintion to Kotlin code, we obtain the core abstraction of krangl : interface DataFrame { val cols : List < DataCol > } abstract class DataCol ( val name : String ) { abstract fun values (): Array <*> } * Implemented as column model to allow for vectorization where possible * Column implementations using nullable types String? , Int? , Double? , Boolean? and Any? * Internal length and type consistency checks (e.g. prevent duplicated column names)","title":"Data model of krangl"},{"location":"data_model/#to-type-or-not-to-type","text":"Static types are cool, but most data has no type It's more robust/fun to use types and they allow for better design Many data attributes are very fluent data class Employee ( val id : Int , val name : String ) val staffStats = listOf ( Employee ( 1 , \"John\" ), Employee ( 2 , \"Anna\" )) . predictNumSickDays () // new type! . addPerformanceMetrics () // new type! . addSalaries () // new type! . correlationAnalysis () // odd generic signature :-| * R/python lack static typing, which make such workflows more fluent/fun to write staff %>% mutate ( sick_days = predictSickDays ( name )) %>% # table with another column left_join ( userPerf ) %>% # and some more columns left_join ( salaries ) %>% # and even more columns select_if ( is.numeric ) %>% correlate ( type = \"spearman\" ) # correlate numeric attributes Defining types is a tedious process. krangl allows to mix typed and untyped data in a tablular data structure: val dataFrame : DataFrame = employee:Employee sales:List<Sale> age:Int address:String salary:Double Employee(23, \"Max\") listOf(Sale(...), Sale()) 23 \"Frankfurt\" 50.3E3 ... ... ... ... ... It implements a pandas / tidyverse like API to create, manipulate, reshape, combine and summarize data frames // aggregations like dataFrame . groupBy ( \"age\" ). count () dataFrame . summarize ( \"mean_salary\" ){ mean ( it [ \"salaray\" ] )} // integration like val df : DataFrame = dataFrame . leftJoin ( otherDF ) // transformations like dataFrame . addColumn ( \"intial\" ){ it [ \"employee\" ] . map < Employee > { it . name . first () }}","title":"To type or not to type?"},{"location":"data_model/#get-your-data-into-krangl","text":"It allows to read from tsv, csv, json, jdbc, e.g. val users = dataFrameOf ( \"firstName\" , \"lastName\" , \"age\" , \"hasSudo\" )( null , \"meyer\" , 23 , null ) val tornados = DataFrame . readCSV ( pathAsStringFileOrUrl ) tornados . writeCSV ( File ( \"tornados.txt.gz\" )) Guess column types & default parameters Built-in missing value support Convert any iterable into a data-frame via extension function + reflection data class Person ( val name : String , val address : String ) val persons : List < Person > = ... val personsDF : DataFrame = persons . asDataFrame () When doing so non-basic properties will be preserved as AnyCol . To further destructured these we can use unfold : data class City ( val name : String , val code : Int ) data class Person ( val name : String , val address : City ) val persons : List < Person > = listOf ( Person ( \"Max\" , City ( \"Dresden\" , 12309 )), Person ( \"Anna\" , City ( \"Berlin\" , 10115 )) ) val personsDF : DataFrame = persons . asDataFrame () personsDF . unfold < City > ( \"address\" ) Both the column and the type are provided.","title":"Get your data into krangl"},{"location":"faq/","text":"How to rewrite common SQL bits with krangl ? select this, that from there where that >5 there . select ( \"this\" , \"that\" ). filter { it [ \"that\" ] gt 5 } Why doesn't krangl provide vectorized comparison operators? Some ( + , - , * , ! ) can be overridden for collections, but others cannot (e.g. all arithmetic and boolean comparison ops) No vectorization for > , && == , etc. in table forumlas \u2192 Use function calls or not so pretty gt , AND , eq , etc. Can we build data science workflows with Kotlin? First, should we? Yes, because R & Python fail to be scalable & robust solutions for data science Java is known for great dependency tooling & scalability Java as a language is less well suited for data-science (cluttered, legacy bits) In Febuary 2018 Kotlin v1.0 was released. Designed with DSLs in mind it comes alongs With great features language such Type Inference, Extension Functions, Data Classes, or Default Parameters, making it a perfect choice to do data science on the JVM . How does krangl compare to what R/dplyr or python/pandas? flights . groupBy ( \"year\" , \"month\" , \"day\" ) . select ({ range ( \"year\" , \"day\" ) }, { listOf ( \"arr_delay\" , \"dep_delay\" ) }) . summarize ( \"mean_arr_delay\" to { it [ \"arr_delay\" ] . mean ( removeNA = true ) }, \"mean_dep_delay\" to { it [ \"dep_delay\" ] . mean ( removeNA = true ) } ) . filter { ( it [ \"mean_arr_delay\" ] gt 30 ) OR ( it [ \"mean_dep_delay\" ] gt 30 ) } And the same snippet written in dplyr : flights %>% group_by ( year , month , day ) %>% select ( year : day , arr_delay , dep_delay ) %>% summarise ( mean_arr_delay = mean ( arr_delay , na.rm = TRUE ), mean_dep_delay = mean ( dep_delay , na.rm = TRUE ) ) %>% filter ( mean_arr_delay > 30 | mean_dep_delay > 30 ) The biggest different are the comparison operators, which Kotlin does not allow to be overridden in a vectorized way. And the same in pandas . {no clue, PR needed here!} How to add columns totals to data-frame? val foo = dataFrameOf ( \"Name\" , \"Duration\" , \"Color\" )( \"Foo\" , 100 , \"Blue\" , \"Goo\" , 200 , \"Red\" , \"Bar\" , 300 , \"Yellow\" ) val columnTotals = foo . cols . map { it . name to when ( it ) { is IntCol -> it . sum () else -> null // ignored column types } }. toMap (). run { dataFrameOf ( keys )( values ) } bindRows ( foo , columnTotals ). print () How to add a column at a certain index position? fun DataFrame . addColumnAtIndex ( columnName : String , index : Int , expression : TableExpression ): DataFrame { return addColumn ( columnName ) { expression ( ec , ec ) } . select ( names . take ( index ) + listOf ( columnName ) + names . takeLast ( index )) } irisData . addColumnAtIndex ( \"foo\" , 1 ) { \"krangl rocks!\" }. print () Further Reading? For a first primer see KotlinConf 2019 slides about Data Science with kotlin krangl presentation at Kotlin-Night in Frankfurt (March 2018) Krangl Introduction A presentation from June 2016 ( sources )","title":"F.A.Q"},{"location":"faq/#how-to-rewrite-common-sql-bits-with-krangl","text":"select this, that from there where that >5 there . select ( \"this\" , \"that\" ). filter { it [ \"that\" ] gt 5 }","title":"How to rewrite common SQL bits with krangl?"},{"location":"faq/#why-doesnt-krangl-provide-vectorized-comparison-operators","text":"Some ( + , - , * , ! ) can be overridden for collections, but others cannot (e.g. all arithmetic and boolean comparison ops) No vectorization for > , && == , etc. in table forumlas \u2192 Use function calls or not so pretty gt , AND , eq , etc.","title":"Why doesn't krangl provide vectorized comparison operators?"},{"location":"faq/#can-we-build-data-science-workflows-with-kotlin","text":"First, should we? Yes, because R & Python fail to be scalable & robust solutions for data science Java is known for great dependency tooling & scalability Java as a language is less well suited for data-science (cluttered, legacy bits) In Febuary 2018 Kotlin v1.0 was released. Designed with DSLs in mind it comes alongs With great features language such Type Inference, Extension Functions, Data Classes, or Default Parameters, making it a perfect choice to do data science on the JVM .","title":"Can we build data science workflows with Kotlin?"},{"location":"faq/#how-does-krangl-compare-to-what-rdplyr-or-pythonpandas","text":"flights . groupBy ( \"year\" , \"month\" , \"day\" ) . select ({ range ( \"year\" , \"day\" ) }, { listOf ( \"arr_delay\" , \"dep_delay\" ) }) . summarize ( \"mean_arr_delay\" to { it [ \"arr_delay\" ] . mean ( removeNA = true ) }, \"mean_dep_delay\" to { it [ \"dep_delay\" ] . mean ( removeNA = true ) } ) . filter { ( it [ \"mean_arr_delay\" ] gt 30 ) OR ( it [ \"mean_dep_delay\" ] gt 30 ) } And the same snippet written in dplyr : flights %>% group_by ( year , month , day ) %>% select ( year : day , arr_delay , dep_delay ) %>% summarise ( mean_arr_delay = mean ( arr_delay , na.rm = TRUE ), mean_dep_delay = mean ( dep_delay , na.rm = TRUE ) ) %>% filter ( mean_arr_delay > 30 | mean_dep_delay > 30 ) The biggest different are the comparison operators, which Kotlin does not allow to be overridden in a vectorized way. And the same in pandas . {no clue, PR needed here!}","title":"How does krangl compare to what R/dplyr or python/pandas?"},{"location":"faq/#how-to-add-columns-totals-to-data-frame","text":"val foo = dataFrameOf ( \"Name\" , \"Duration\" , \"Color\" )( \"Foo\" , 100 , \"Blue\" , \"Goo\" , 200 , \"Red\" , \"Bar\" , 300 , \"Yellow\" ) val columnTotals = foo . cols . map { it . name to when ( it ) { is IntCol -> it . sum () else -> null // ignored column types } }. toMap (). run { dataFrameOf ( keys )( values ) } bindRows ( foo , columnTotals ). print ()","title":"How to add columns totals to data-frame?"},{"location":"faq/#how-to-add-a-column-at-a-certain-index-position","text":"fun DataFrame . addColumnAtIndex ( columnName : String , index : Int , expression : TableExpression ): DataFrame { return addColumn ( columnName ) { expression ( ec , ec ) } . select ( names . take ( index ) + listOf ( columnName ) + names . takeLast ( index )) } irisData . addColumnAtIndex ( \"foo\" , 1 ) { \"krangl rocks!\" }. print ()","title":"How to add a column at a certain index position?"},{"location":"faq/#further-reading","text":"For a first primer see KotlinConf 2019 slides about Data Science with kotlin krangl presentation at Kotlin-Night in Frankfurt (March 2018) Krangl Introduction A presentation from June 2016 ( sources )","title":"Further Reading?"},{"location":"reshape/","text":"Reshaping Data Note For a primer on tidy data read http://garrettgman.github.io/tidying/ {% endhint %} Example: Data Reshaping with krangl val climate = dataFrameOf ( \"city\" , \"coast_distance\" , \"1995\" , \"2000\" , \"2005\" )( \"Dresden\" , 400 , 343 , 252 , 423 , \"Frankfurt\" , 534 , 534 , 435 , 913 ) city coast_distance 1995 2000 2005 Dresden 400 343 252 423 Frankfurt 534 534 435 913 climate . gather ( \"year\" , \"rainfall\" , columns = { matches ( \"[0-9]*\" )} ) city coast_distance year rainfall Dresden 400 1995 343 Frankfurt 534 1995 534 Dresden 400 2000 252 Frankfurt 534 2000 435 Dresden 400 2005 423 Frankfurt 534 2005 913 ??? colummns use function literals again, with column names type as receiver Example: Data Ingestion with krangl dataFrameOf ( \"user\" )( \"brandl,holger,37\" ) . apply { print () } . separate ( \"user\" , listOf ( \"last_name\" , \"first_name\" , \"age\" ), convert = true ) . apply { print () } . apply { glimpse () } user brandl,holger,37 last_name first_name age brandl holger 37 DataFrame with 1 observations last_name : [Str] , [brandl] first_name : [Str] , [holger] age : [Int] , [37] Digest objects into attribute columns Cherry-pick properties with Iterable<T>.deparseRecords val deparsedDF = records . deparseRecords { mapOf ( \"age\" to it . age , \"weight\" to it . mean_weight ) } Be lazy and use reflection data class Person ( val name : String , val age : Int ) val persons : List < Person > = listOf ( Person ( \"Max\" , 23 ), Person ( \"Anna\" , 43 )) val personsDF : DataFrame = persons . asDataFrame () personsDF age name 23 Max 43 Anna List/object columns krangl supports arbitrary types per column val persons : DataFrame = dataFrameOf ( \"person\" )( persons ) persons person Person(name=Max, age=23) Person(name=Anna, age=43) personsDF2 . glimpse () DataFrame with 2 observations person : [Any] , [Person(name=Max, age=23), Person(name=Anna, age=43)] Unfold objects into columns similar to separate() but for object columns data class Person ( val name : String , val age : Int ) val persons : Iterable < Person > = listOf ( Person ( \"Max\" , 22 ), Person ( \"Anna\" , 23 )) val df : DataFrame = dataFrameOf ( \"person\" )( persons ) df . names [\"person\"] -- Expand properties of person into columns via reflection var personsDF = df . unfold < Person > ( \"person\" , keep = true ) // unfold<Person>(\"person\", select=listOf(\"age\")) personsDF . names [\"person\", \"name\", \"age\"] Let krangl define the schema Infer a schema with irisData . printDataClassSchema ( \"Iris\" ) which makes krangl to print the Kotlin data class schema for data frame: data class Iris ( val sepalLength : Double , val sepalWidth : Double , val petalLength : Double , val petalWidth : Double , val species : String ) val records : Iterable < Iris > = irisData . rowsAs < Iris > () Paste it back into workflow code and continue with typed objects! records . take ( 1 ) [ Iris(sepalLength=5.1, sepalWidth=3.5, petalLength=1.4, petalWidth=0.2, species=setosa) ]","title":"Reshape Tabular Data"},{"location":"reshape/#reshaping-data","text":"Note For a primer on tidy data read http://garrettgman.github.io/tidying/ {% endhint %}","title":"Reshaping Data"},{"location":"reshape/#example-data-reshaping-with-krangl","text":"val climate = dataFrameOf ( \"city\" , \"coast_distance\" , \"1995\" , \"2000\" , \"2005\" )( \"Dresden\" , 400 , 343 , 252 , 423 , \"Frankfurt\" , 534 , 534 , 435 , 913 ) city coast_distance 1995 2000 2005 Dresden 400 343 252 423 Frankfurt 534 534 435 913 climate . gather ( \"year\" , \"rainfall\" , columns = { matches ( \"[0-9]*\" )} ) city coast_distance year rainfall Dresden 400 1995 343 Frankfurt 534 1995 534 Dresden 400 2000 252 Frankfurt 534 2000 435 Dresden 400 2005 423 Frankfurt 534 2005 913 ??? colummns use function literals again, with column names type as receiver","title":"Example: Data Reshaping with krangl"},{"location":"reshape/#example-data-ingestion-with-krangl","text":"dataFrameOf ( \"user\" )( \"brandl,holger,37\" ) . apply { print () } . separate ( \"user\" , listOf ( \"last_name\" , \"first_name\" , \"age\" ), convert = true ) . apply { print () } . apply { glimpse () } user brandl,holger,37 last_name first_name age brandl holger 37 DataFrame with 1 observations last_name : [Str] , [brandl] first_name : [Str] , [holger] age : [Int] , [37]","title":"Example: Data Ingestion with krangl"},{"location":"reshape/#digest-objects-into-attribute-columns","text":"Cherry-pick properties with Iterable<T>.deparseRecords val deparsedDF = records . deparseRecords { mapOf ( \"age\" to it . age , \"weight\" to it . mean_weight ) } Be lazy and use reflection data class Person ( val name : String , val age : Int ) val persons : List < Person > = listOf ( Person ( \"Max\" , 23 ), Person ( \"Anna\" , 43 )) val personsDF : DataFrame = persons . asDataFrame () personsDF age name 23 Max 43 Anna","title":"Digest objects into attribute columns"},{"location":"reshape/#listobject-columns","text":"krangl supports arbitrary types per column val persons : DataFrame = dataFrameOf ( \"person\" )( persons ) persons person Person(name=Max, age=23) Person(name=Anna, age=43) personsDF2 . glimpse () DataFrame with 2 observations person : [Any] , [Person(name=Max, age=23), Person(name=Anna, age=43)]","title":"List/object columns"},{"location":"reshape/#unfold-objects-into-columns","text":"similar to separate() but for object columns data class Person ( val name : String , val age : Int ) val persons : Iterable < Person > = listOf ( Person ( \"Max\" , 22 ), Person ( \"Anna\" , 23 )) val df : DataFrame = dataFrameOf ( \"person\" )( persons ) df . names [\"person\"] -- Expand properties of person into columns via reflection var personsDF = df . unfold < Person > ( \"person\" , keep = true ) // unfold<Person>(\"person\", select=listOf(\"age\")) personsDF . names [\"person\", \"name\", \"age\"]","title":"Unfold objects into columns"},{"location":"reshape/#let-krangl-define-the-schema","text":"Infer a schema with irisData . printDataClassSchema ( \"Iris\" ) which makes krangl to print the Kotlin data class schema for data frame: data class Iris ( val sepalLength : Double , val sepalWidth : Double , val petalLength : Double , val petalWidth : Double , val species : String ) val records : Iterable < Iris > = irisData . rowsAs < Iris > () Paste it back into workflow code and continue with typed objects! records . take ( 1 ) [ Iris(sepalLength=5.1, sepalWidth=3.5, petalLength=1.4, petalWidth=0.2, species=setosa) ]","title":"Let krangl define the schema"},{"location":"time-series/","text":"Time Series Those who have knowledge, don't predict. Those who predict, don't have knowledge. - Lao Tzu Basics Analyzing time series works like a breeze with krangl . Conceptually, time-series are simply tables with a java.util.Date column. They can be analyzed by means of grouping and aggregation as any other data frame. {todo} file a ticket if you find this interesting :-)","title":"Time Series"},{"location":"time-series/#time-series","text":"Those who have knowledge, don't predict. Those who predict, don't have knowledge. - Lao Tzu","title":"Time Series"},{"location":"time-series/#basics","text":"Analyzing time series works like a breeze with krangl . Conceptually, time-series are simply tables with a java.util.Date column. They can be analyzed by means of grouping and aggregation as any other data frame. {todo} file a ticket if you find this interesting :-)","title":"Basics"},{"location":"tutorials/data_vis/","text":"How to visualize tabular data when using krangl? There are multiple visualization engines that are compatible with krangl . lets-plot lets-plot is an open-source plotting library for statistical data which is written entirely in the Kotlin programming language. For new users of krangl, we strongly recommend to use lets-plot because of its stability and ease of use. For a fully worked out tutorial see the jupyter workbook sleep_patterns.ipynb . Example import jetbrains.letsPlot.* irisData . letsPlot { x = \"Sepal.Width\" ; y = \"Sepal.Length\" ; color = \"Species\" } + geomPoint () kravis kravis Implements a grammar to create a wide range of plots using a standardized set of verbs. kravis essentially wrap ggplot2 from R. The latter it will access via different backends like a local installation, docker or Rserve. It is more versatile compared to lets-plots because it supports to full ggplot2 grammar, but relies on R as non-java binary as dependency. Example import kravis.* import krangl.irisData irisData . ggplot ( \"Species\" to x , \"Petal.Length\" to y ) . geomBoxplot () . geomPoint ( position = PositionJitter ( width = 0.1 ), alpha = 0.3 ) . title ( \"Petal Length by Species\" ) Other options There are great other libaries available, which typically don't work with krangl yet, but provide awesome ways to visualize data. See here for a listing.","title":"Data Visualization"},{"location":"tutorials/data_vis/#how-to-visualize-tabular-data-when-using-krangl","text":"There are multiple visualization engines that are compatible with krangl .","title":"How to visualize tabular data when using krangl?"},{"location":"tutorials/data_vis/#lets-plot","text":"lets-plot is an open-source plotting library for statistical data which is written entirely in the Kotlin programming language. For new users of krangl, we strongly recommend to use lets-plot because of its stability and ease of use. For a fully worked out tutorial see the jupyter workbook sleep_patterns.ipynb . Example import jetbrains.letsPlot.* irisData . letsPlot { x = \"Sepal.Width\" ; y = \"Sepal.Length\" ; color = \"Species\" } + geomPoint ()","title":"lets-plot"},{"location":"tutorials/data_vis/#kravis","text":"kravis Implements a grammar to create a wide range of plots using a standardized set of verbs. kravis essentially wrap ggplot2 from R. The latter it will access via different backends like a local installation, docker or Rserve. It is more versatile compared to lets-plots because it supports to full ggplot2 grammar, but relies on R as non-java binary as dependency. Example import kravis.* import krangl.irisData irisData . ggplot ( \"Species\" to x , \"Petal.Length\" to y ) . geomBoxplot () . geomPoint ( position = PositionJitter ( width = 0.1 ), alpha = 0.3 ) . title ( \"Petal Length by Species\" )","title":"kravis"},{"location":"tutorials/data_vis/#other-options","text":"There are great other libaries available, which typically don't work with krangl yet, but provide awesome ways to visualize data. See here for a listing.","title":"Other options"},{"location":"tutorials/machine_learning/","text":"Machine Learning krangl integrates nicely with existing JVM machine learning libraries. Machine Learning with SMILE The https://github.com/haifengl/smile projects contains tons of implementations needed for modern data science. Among others Classification Support Vector Machines, Decision Trees, AdaBoost, Gradient Boosting, Random Forest, Logistic Regression, Neural Networks, RBF Networks, Maximum Entropy Classifier, KNN, Na\u00efve Bayesian, Fisher/Linear/Quadratic/Regularized Discriminant Analysis. Regression Support Vector Regression, Gaussian Process, Regression Trees, Gradient Boosting, Random Forest, RBF Networks, OLS, LASSO, Ridge Regression. Feature Selection Genetic Algorithm based Feature Selection, Ensemble Learning based Feature Selection, Signal Noise ratio, Sum Squares ratio. Clustering BIRCH, CLARANS, DBScan, DENCLUE, Deterministic Annealing, K-Means, X-Means, G-Means, Neural Gas, Growing Neural Gas, Hierarchical Clustering, Sequential Information Bottleneck, Self-Organizing Maps, Spectral Clustering, Minimum Entropy Clustering. Manifold learning IsoMap, LLE, Laplacian Eigenmap, t-SNE, PCA, Kernel PCA, Probabilistic PCA, GHA, Random Projection, MDS Nearest Neighbor Search BK-Tree, Cover Tree, KD-Tree, LSH. Sequence Learning Hidden Markov Model, Conditional Random Field. Natural Language Processing Tokenizer, Keyword Extractor, Stemmer, POS Tagging, Relevance Ranking Example It's easy to use krangl and smile to build data science workflows. Here is an example for doing a PCA. val irisArray = irisData . remove ( \"Species\" ). toArray () //barchart pca . varianceProportion . withIndex (). plot ({ it . index }, { it . value }). geomCol (). show () val projection = pca . setProjection ( 2 ). projection // merge back in the group labels to color scatter var pc12 = projection . transpose (). array (). withIndex (). deparseRecords { mapOf ( \"index\" to it . index + 1 , \"x\" to it . value [ 0 ] , \"y\" to it . value [ 1 ] ) } pc12 = pc12 . leftJoin ( irisData . addColumn ( \"index\" ) { rowNumber }) pc12 . plot ( x = \"x\" , y = \"y\" , color = \"Species\" ). geomPoint (). show ()","title":"Machine Learning"},{"location":"tutorials/machine_learning/#machine-learning","text":"krangl integrates nicely with existing JVM machine learning libraries.","title":"Machine Learning"},{"location":"tutorials/machine_learning/#machine-learning-with-smile","text":"The https://github.com/haifengl/smile projects contains tons of implementations needed for modern data science. Among others Classification Support Vector Machines, Decision Trees, AdaBoost, Gradient Boosting, Random Forest, Logistic Regression, Neural Networks, RBF Networks, Maximum Entropy Classifier, KNN, Na\u00efve Bayesian, Fisher/Linear/Quadratic/Regularized Discriminant Analysis. Regression Support Vector Regression, Gaussian Process, Regression Trees, Gradient Boosting, Random Forest, RBF Networks, OLS, LASSO, Ridge Regression. Feature Selection Genetic Algorithm based Feature Selection, Ensemble Learning based Feature Selection, Signal Noise ratio, Sum Squares ratio. Clustering BIRCH, CLARANS, DBScan, DENCLUE, Deterministic Annealing, K-Means, X-Means, G-Means, Neural Gas, Growing Neural Gas, Hierarchical Clustering, Sequential Information Bottleneck, Self-Organizing Maps, Spectral Clustering, Minimum Entropy Clustering. Manifold learning IsoMap, LLE, Laplacian Eigenmap, t-SNE, PCA, Kernel PCA, Probabilistic PCA, GHA, Random Projection, MDS Nearest Neighbor Search BK-Tree, Cover Tree, KD-Tree, LSH. Sequence Learning Hidden Markov Model, Conditional Random Field. Natural Language Processing Tokenizer, Keyword Extractor, Stemmer, POS Tagging, Relevance Ranking","title":"Machine Learning with SMILE"},{"location":"tutorials/machine_learning/#example","text":"It's easy to use krangl and smile to build data science workflows. Here is an example for doing a PCA. val irisArray = irisData . remove ( \"Species\" ). toArray () //barchart pca . varianceProportion . withIndex (). plot ({ it . index }, { it . value }). geomCol (). show () val projection = pca . setProjection ( 2 ). projection // merge back in the group labels to color scatter var pc12 = projection . transpose (). array (). withIndex (). deparseRecords { mapOf ( \"index\" to it . index + 1 , \"x\" to it . value [ 0 ] , \"y\" to it . value [ 1 ] ) } pc12 = pc12 . leftJoin ( irisData . addColumn ( \"index\" ) { rowNumber }) pc12 . plot ( x = \"x\" , y = \"y\" , color = \"Species\" ). geomPoint (). show ()","title":"Example"},{"location":"tutorials/report_rendering/","text":"Data science workflows written with Kotlin can be rendered to html, pdf, and markdown using Jupyter. To do so we need a kernel. A kernel provides programming language support in Jupyter. IPython is the default kernel. Additional kernels include R, Julia, and many more. Two competing kernels are available for Kotlin https://github.com/ligee/kotlin-jupyter More established Backed by JB Friendly and responsive developers Not really active https://github.com/twosigma/beakerx a collection of JVM kernels and interactive widgets for plotting, tables, auto-translation, and other extensions to Jupyter Notebook. Very active, fast progress Friendly and very responsive developers Not just a kernel Display handler registry in kernel krangl.beakerx.TableDisplayer.register() In our opinion, Kotlin-powered Jupyter notebooks are definitely cool, but lacks efficiency because of missing tooling (error checking, completion, refactoring): Build reports embedding code and results However, the kernel can be used for literate programming, which enables result consistency and streamline communication by building reports from code So finally we want to develop data workflows interactively using plain and simple code. Similar to how it is possible with R via the well known tool chain built around knitr -> pandoc : Similary, in python this can be achieved by startin with markdown -> notedown + nbconvert Can we do this with Kotlin? Let's consider the following example //' ## Flowers Analysis //' The iris flower //' ![](https://goo.gl/tTbZMq) //@file:MavenRepository(\"bintray-plugins\",\"http://jcenter.bintray.com\") @file : DependsOnMaven ( \"com.github.holgerbrandl.krangl:krangl:0.15.6\" ) import krangl.* //' The first records in the input data (which is bundled with krangl) are irisData //' The structure of the input data is irisData . glimpse () //' Calculate mean petal val summarizeDf : DataFrame = irisData . groupBy ( \"Species\" ) . summarize ( \"mean_petal_width\" ) { it [ \"Petal.Width\" ] . mean () } //' Print the summarized data summarizeDf . print () //' Conclusion: Iris flowers of species _virginica_ have on average the largest petal width. An kts->html conversion could be impelmented as follows: inputScript = krangl_example_report.kts reportName = $( basename $inputScript .kts ) # https://www.r-project.org/ Rscript - ${ inputScript } << \"EOF\" knitr::spin ( commandArgs ( T )[ 1 ] , doc = \"^//'[ ]?\" , knit = F ) EOF # https://github.com/holgerbrandl/kscript kscript -t 'lines.map { it.replace(\"{r }\", \"\")}.print()' ${ reportName } .Rmd > ${ reportName } .md # https://github.com/aaren/notedown notedown ${ reportName } .md > ${ reportName } .ipynb # http://jupyter.org/install jupyter nbconvert --ExecutePreprocessor.kernel_name = kotlin \\ --execute --to html ${ reportName } .ipynb --output ${ reportName } Proof-of-Concept. :-)","title":"Report Rendering"},{"location":"tutorials/report_rendering/#build-reports-embedding-code-and-results","text":"However, the kernel can be used for literate programming, which enables result consistency and streamline communication by building reports from code So finally we want to develop data workflows interactively using plain and simple code. Similar to how it is possible with R via the well known tool chain built around knitr -> pandoc : Similary, in python this can be achieved by startin with markdown -> notedown + nbconvert Can we do this with Kotlin? Let's consider the following example //' ## Flowers Analysis //' The iris flower //' ![](https://goo.gl/tTbZMq) //@file:MavenRepository(\"bintray-plugins\",\"http://jcenter.bintray.com\") @file : DependsOnMaven ( \"com.github.holgerbrandl.krangl:krangl:0.15.6\" ) import krangl.* //' The first records in the input data (which is bundled with krangl) are irisData //' The structure of the input data is irisData . glimpse () //' Calculate mean petal val summarizeDf : DataFrame = irisData . groupBy ( \"Species\" ) . summarize ( \"mean_petal_width\" ) { it [ \"Petal.Width\" ] . mean () } //' Print the summarized data summarizeDf . print () //' Conclusion: Iris flowers of species _virginica_ have on average the largest petal width. An kts->html conversion could be impelmented as follows: inputScript = krangl_example_report.kts reportName = $( basename $inputScript .kts ) # https://www.r-project.org/ Rscript - ${ inputScript } << \"EOF\" knitr::spin ( commandArgs ( T )[ 1 ] , doc = \"^//'[ ]?\" , knit = F ) EOF # https://github.com/holgerbrandl/kscript kscript -t 'lines.map { it.replace(\"{r }\", \"\")}.print()' ${ reportName } .Rmd > ${ reportName } .md # https://github.com/aaren/notedown notedown ${ reportName } .md > ${ reportName } .ipynb # http://jupyter.org/install jupyter nbconvert --ExecutePreprocessor.kernel_name = kotlin \\ --execute --to html ${ reportName } .ipynb --output ${ reportName } Proof-of-Concept. :-)","title":"Build reports embedding code and results"},{"location":"tutorials/statistics/","text":"Regression Analysis Using libaries http://commons.apache.org/proper/commons-math/ and https://github.com/chen0040/java-glm, krangl allows to perform R-like regression analyses. Example: How to fit a linear regression model per group? val irisModel = irisData . groupBy ( \"Species\" ) . summarize ( \"lm\" ) { val x = it [ \"Sepal.Length\" ] . asDoubles (). filterNotNull (). toDoubleArray () val y = it [ \"Sepal.Width\" ] . asDoubles (). filterNotNull (). toDoubleArray () val xTransposed = MatrixUtils . createRealMatrix ( arrayOf ( x )). transpose (). data SimpleRegression (). apply { addObservations ( xTransposed , y ) } } . unfold < SimpleRegression > ( \"lm\" , properties = listOf ( \"intercept\" , \"slope\" )) Species lm slope intercept setosa org.apache.commons.math3.stat.regression.SimpleRegression@66133adc 0.798 -0.5694 versicolor org.apache.commons.math3.stat.regression.SimpleRegression@7bfcd12c 0.319 0.8721 virginica org.apache.commons.math3.stat.regression.SimpleRegression@42f30e0a 0.2318 1.446","title":"Statistics"},{"location":"tutorials/statistics/#regression-analysis","text":"Using libaries http://commons.apache.org/proper/commons-math/ and https://github.com/chen0040/java-glm, krangl allows to perform R-like regression analyses. Example: How to fit a linear regression model per group? val irisModel = irisData . groupBy ( \"Species\" ) . summarize ( \"lm\" ) { val x = it [ \"Sepal.Length\" ] . asDoubles (). filterNotNull (). toDoubleArray () val y = it [ \"Sepal.Width\" ] . asDoubles (). filterNotNull (). toDoubleArray () val xTransposed = MatrixUtils . createRealMatrix ( arrayOf ( x )). transpose (). data SimpleRegression (). apply { addObservations ( xTransposed , y ) } } . unfold < SimpleRegression > ( \"lm\" , properties = listOf ( \"intercept\" , \"slope\" )) Species lm slope intercept setosa org.apache.commons.math3.stat.regression.SimpleRegression@66133adc 0.798 -0.5694 versicolor org.apache.commons.math3.stat.regression.SimpleRegression@7bfcd12c 0.319 0.8721 virginica org.apache.commons.math3.stat.regression.SimpleRegression@42f30e0a 0.2318 1.446","title":"Regression Analysis"}]}